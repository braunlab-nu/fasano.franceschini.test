<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Fasano-Franceschini Test: an Implementation of a 2-Dimensional Kolmogorov-Smirnov test in R • fasano.franceschini.test</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Fasano-Franceschini Test: an Implementation of a 2-Dimensional Kolmogorov-Smirnov test in R">
<meta property="og:description" content="fasano.franceschini.test">
<meta property="og:image" content="/logo.png">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">fasano.franceschini.test</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">1.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/fasano-franceschini-test.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/nesscoder/fasano.franceschini.test/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="fasano-franceschini-test_files/header-attrs-2.6/header-attrs.js"></script><script src="fasano-franceschini-test_files/jquery-1.11.3/jquery.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1">
<link href="fasano-franceschini-test_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet">
<script src="fasano-franceschini-test_files/bootstrap-3.3.5/js/bootstrap.min.js"></script><script src="fasano-franceschini-test_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script><script src="fasano-franceschini-test_files/bootstrap-3.3.5/shim/respond.min.js"></script><script src="fasano-franceschini-test_files/navigation-1.1/tabsets.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Fasano-Franceschini Test: an Implementation of a 2-Dimensional Kolmogorov-Smirnov test in R</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/nesscoder/fasano.franceschini.test/blob/master/vignettes/fasano-franceschini-test.Rmd"><code>vignettes/fasano-franceschini-test.Rmd</code></a></small>
      <div class="hidden name"><code>fasano-franceschini-test.Rmd</code></div>

    </div>

    
    
<style>
p.caption{
  font-size: 0.75em;
  text-align: left;
}
</style>
<div id="sec:abstact" class="section level1">
<h1 class="hasAnchor">
<a href="#sec:abstact" class="anchor"></a>Abstract</h1>
<p>The univariate Kolmogorov-Smirnov (KS) test is a non–parametric
statistical test designed to assess whether a set of data is consistent
with a given probability distribution (or, in the two-sample case,
whether the two samples come from the same underlying distribution). The
versatility of the KS test has made it a cornerstone of statistical
analysis and is commonly used across the scientific disciplines.
However, the test proposed by Kolmogorov and Smirnov does not naturally
extend to multidimensional distributions. Here, we present the
<code>fasano.franceschini.test</code> package, an <strong>R</strong> implementation of the 2-D
KS two–sample test as defined by Fasano and Franceschini<span class="citation">(<a href="#ref-Fasano1987" role="doc-biblioref">1</a>)</span>.
The <code>fasano.franceschini.test</code> package provides three improvements over
the current 2-D KS test on the Comprehensive <strong>R</strong> Archive Network
(CRAN): (i) the Fasano and Franceschini test has been shown to run in
<span class="math inline">\(O(n^2)\)</span> versus the Peacock implementation which runs in <span class="math inline">\(O(n^3)\)</span>; (ii)
the package implements a procedure for handling ties in the data; and
(iii) the package implements a parallelized bootstrapping procedure for
improved significance testing. Ultimately, the
<code>fasano.franceschini.test</code> package presents a robust statistical test
for analyzing random samples defined in 2-dimensions.</p>
</div>
<div id="sec:intro" class="section level1">
<h1 class="hasAnchor">
<a href="#sec:intro" class="anchor"></a>Introduction</h1>
<p>The Kolmogorov–Smirnov (KS) is a non–parametric, univariate
statistical test designed to assess whether a set of data is consistent
with a given probability distribution (or, in the two-sample case,
whether the two samples come from the same underlying distribution).
First derived by Kolmogorov and Smirnov in a series of papers
<span class="citation">(<a href="#ref-Kolmogorov1933" role="doc-biblioref">2</a>–<a href="#ref-Smirnov1948" role="doc-biblioref">8</a>)</span>, the one-sample KS test
defines the distribution of the quantity <span class="math inline">\(D_{KS}\)</span>, the maximal absolute
difference between the empirical cumulative distribution function (CDF)
of a set of values and a reference probability distribution. Kolmogorov
and Smirnov’s key insight was proving the distribution of <span class="math inline">\(D_{KS}\)</span> was
independent of the CDFs being tested. Thus, the test can effectively be
used to compare any univariate empirical data distribution to any
continuous univariate reference distribution. The two-sample KS test
could further be used to compare any two univariate empirical data
distributions against each other to determine if they are drawn from the
same underlying univariate distribution.</p>
<p>The nonparametric versatility of the univariate KS test has made it a
cornerstone of statistical analysis and is commonly used across the
scientific disciplines <span class="citation">(<a href="#ref-Atasoy2017" role="doc-biblioref">9</a>–<a href="#ref-Kaczanowska2021" role="doc-biblioref">14</a>)</span>. However, the KS test as
proposed by Kolmogorov and Smirnov does not naturally extend to
distributions in more than one dimension. Fortunately, a solution to the
dimensionality issue was articulated by Peacock <span class="citation">(<a href="#ref-Peacock1983" role="doc-biblioref">15</a>)</span> and later
extended by Fasano and Franceschini <span class="citation">(<a href="#ref-Fasano1987" role="doc-biblioref">1</a>)</span>.</p>
<p>Currently, only the Peacock implementation of the 2-D two-sample KS test
is available in <strong>R</strong> <span class="citation">(<a href="#ref-R" role="doc-biblioref">16</a>)</span> with the <code>Peacock.test</code> package via the <code>peacock2()</code> function, but this has
been shown to be markedly slower than the Fasano and Franceschini
algorithm <span class="citation">(<a href="#ref-Lopes2007" role="doc-biblioref">17</a>)</span>. A <strong>C</strong> implementation of the Fasano–Franceschini
test is available in <span class="citation">(<a href="#ref-numericalRecipes" role="doc-biblioref">18</a>)</span>; however, arguments have been
made to the validity of the implementation of the test not being
distribution-free <span class="citation">(<a href="#ref-Babu2006" role="doc-biblioref">19</a>)</span>. Furthermore, in the <strong>C</strong> implementation,
statistical testing is based on a fit to Monte Carlo simulation that is
only valid for significance levels <span class="math inline">\(\alpha \lessapprox 0.20\)</span>.</p>
<p>Here we present the <code>fasano.franceschini.test</code> package as an <strong>R</strong> implementation of the 2-D two-sample
KS test described by Fasano and Franceschini <span class="citation">(<a href="#ref-Fasano1987" role="doc-biblioref">1</a>)</span>. The <code>fasano.franceschini.test</code> package
provides two improvements over the current 2-D KS test available on the
Comprehensive Archive Network (CRAN): (i) the Fasano and Franceschini
test has been shown to run in <span class="math inline">\(O(n^2)\)</span> versus the Peacock implementation
which runs in <span class="math inline">\(O(n^3)\)</span>; and (ii) the package implements a bootstrapping
procedure for improved significance testing and mitigates the
limitations of the test brought noted by <span class="citation">(<a href="#ref-Babu2006" role="doc-biblioref">19</a>)</span>.</p>
</div>
<div id="sec:models" class="section level1">
<h1 class="hasAnchor">
<a href="#sec:models" class="anchor"></a>Models and software</h1>
<div id="d-kolmogorovsmirnov-test" class="section level2">
<h2 class="hasAnchor">
<a href="#d-kolmogorovsmirnov-test" class="anchor"></a>1-D Kolmogorov–Smirnov Test</h2>
<p>The Kolmogorov–Smirnov (KS) test is a non–parametric method for
determining whether a sample is consistent with a given probability
distribution <span class="citation">(<a href="#ref-Stephens1992a" role="doc-biblioref">20</a>)</span>. In one dimension, the Kolmogorov-Smirnov
statistic (<span class="math inline">\(D_{KS}\)</span>) is the defined by the maximum absolute difference
between the cumulative density functions of the data and model
(one–sample), or between the two data sets (two–sample), as
illustrated in <strong>Figure <a href="#fig:kstest1D" reference-type="ref" reference="fig:kstest1D">1</a></strong>.</p>
<center>
<div class="figure">
<img src="pdfvsCDF.png" id="fig:kstest1D" style="width:75.0%" alt=""><p class="caption"><strong>Figure 1</strong> | <strong>LEFT:</strong> Probability density function (PDF) of two
normal distributions: orange sample 1,
<span class="math inline">\(\mathcal{N}(\mu = 0,\,\sigma^{2} = 1)\)</span>; blue sample 2,
<span class="math inline">\(\mathcal{N}(\mu = 5,\,\sigma^{2} = 1)\)</span>. <strong>RIGHT:</strong> Cumulative density
functions (CDF) of the two PDFs; the black dotted line represents the
maximal absolute difference between the CDFs
(<span class="math inline">\(D_{KS}\)</span>).</p>
</div>
</center>
<p>In the large–sample limit (<span class="math inline">\(n \geq 80\)</span>), it can be shown <span class="citation">(<a href="#ref-Kendall1946" role="doc-biblioref">21</a>)</span>
that <span class="math inline">\(D_{KS}\)</span> converges in distribution to</p>
<span class="math display" id="eq:1">\[\begin{equation}
D_{KS} \overset{d}{\rightarrow} \Phi(\lambda) = 2 \sum_{k=1}^{\infty} -1^{k-1}e^{-2k^2\lambda^2} \,.
\tag{1}
\end{equation}\]</span>
<p>In the one-sample case with a sample of size <span class="math inline">\(n\)</span>, the <span class="math inline">\(p\)</span> value is given
by </p>
<span class="math display" id="eq:2">\[\begin{equation}
\mathbb{P}(D &gt; observed) = \Phi ( D\sqrt{n})\,;
\tag{2}
\end{equation}\]</span>
<p>in the two-sample case, the <span class="math inline">\(p\)</span> value is given by</p>
<span class="math display" id="eq:3">\[\begin{equation}
\mathbb{P}(D &gt; observed) = \Phi \left( D\sqrt{\frac{n_1n_2}{n_1+n_2}} \right)\,.
\tag{3}
\end{equation}\]</span>
<p>where <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> are the number of observations in the first and
second samples respectively.</p>
</div>
<div id="higher-dimensional-variations-peacock-test-1983-and-fasanofranceschini-test-1987" class="section level2">
<h2 class="hasAnchor">
<a href="#higher-dimensional-variations-peacock-test-1983-and-fasanofranceschini-test-1987" class="anchor"></a>Higher dimensional variations: Peacock Test (1983) and Fasano–Franceschini Test (1987)</h2>
<p>Extending the above to two or higher dimension is complicated by the
fact that CDFs are not well-defined in more than one dimension. In 2-D,
there are 4 ways (3 independent) of defining the cumulative
distribution, since the direction in which we order the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>
points is arbitrary (<strong>Figure
<a href="#fig:kstest2Dissue" reference-type="ref" reference="fig:kstest2Dissue">2</a></strong>); more generally, in <span class="math inline">\(k\)</span>-dimensional
space there are <span class="math inline">\(2^{k}-1\)</span> independent ways of defining the cumulative
distribution function <span class="citation">(<a href="#ref-Peacock1983" role="doc-biblioref">15</a>)</span>.</p>
<center>
<div class="figure">
<img src="CDF2Dissue.png" id="fig:kstest2Dissue" style="width:75.0%" alt=""><p class="caption"><strong>Figure 2</strong> | Four ways (3 independent) of defining the cumulative
distribution for a given point in 2-D. Here, the orange point <span class="math inline">\((X,Y)\)</span> is
chosen as the origin; the density of observations may be integrated as
<span class="math inline">\(\mathbb{P}(x &lt; X, y &gt; Y)\)</span> (A); <span class="math inline">\(\mathbb{P}(x &lt; X \cup y &lt; Y)\)</span> (B);
<span class="math inline">\(\mathbb{P}(x &lt; X, y &lt; Y)\)</span> (C); <span class="math inline">\(\mathbb{P}(x &gt; X, y &gt; Y)\)</span>
(D).</p>
</div>
</center>
<p><span class="citation">(<a href="#ref-Peacock1983" role="doc-biblioref">15</a>)</span> solved the higher dimensionality issue by defining the
2-D test statistic as the largest difference between the empirical and
theoretical cumulative distributions, after taking all possible ordering
combinations into account. Peacock’s test thus computes the total
probability—i.e. fraction of data—in each of the four quadrants
around all possible tuples in the data. For example, for <span class="math inline">\(n\)</span> points in a
two-dimensional space, the empirical cumulative distribution functions
is calculated in the <span class="math inline">\(4n^2\)</span> quadrants of the plane defined by all pairs
<span class="math inline">\((X_i, Y_j): i,j\in[1,n]\)</span>, where <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_j\)</span> are any observed
value of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> (whether or not they are observed as a pair). There
are <span class="math inline">\(n^2\)</span> such pairs, each of which can define four quadrants in the 2-D
plane; by ranging over all possible pairs of data points and quadrants,
the 2-dimensional <span class="math inline">\(D\)</span> statistic is defined by the maximal difference of
the integrated probabilities between samples.</p>
<p>The variation defined by <span class="citation">(<a href="#ref-Fasano1987" role="doc-biblioref">1</a>)</span> was to only consider quadrants
centered on each observed <span class="math inline">\((x, y)\)</span> pair to compute the cumulative
distribution functions. That is, rather than looking over all <span class="math inline">\(n^2\)</span>
points <span class="math inline">\({(X_i, Y_j): i,j \in [1,n]}\)</span>, Fasano and Franceschini only use
the observed <span class="math inline">\(n\)</span> points <span class="math inline">\({(X_i, Y_i): i \in [1,n]}\)</span>. Thus for any given
<span class="math inline">\(n\)</span> points in a two-dimensional space, those <span class="math inline">\(n\)</span> points define <span class="math inline">\(4n\)</span>
(rather than <span class="math inline">\(4n^2\)</span>) quadrants. The procedure is illustrated in <strong>Figure
<a href="#fig:kstest2D" reference-type="ref" reference="fig:kstest2D">3</a></strong>. The
algorithm loops through each point in one sample in turn to define the
origin of 4 quadrants (grey dotted lines in <strong>Figure
<a href="#fig:kstest2D" reference-type="ref" reference="fig:kstest2D">3</a></strong>).
The fraction of points in each sample is computed in each quadrant, and
the quadrant with the maximal difference is designated with the current
maximum for the specified origin. By iterating over all data points and
quadrants, the test statistic <span class="math inline">\(D_{FF,1}\)</span> is defined by the maximal
difference of the integrated probabilities between samples in any
quadrant for any origin from the first sample. In <strong>Figure
<a href="#fig:kstest2D" reference-type="ref" reference="fig:kstest2D">3</a></strong>,
using the orange point as the origin, the maximal difference is
<span class="math inline">\(D_{FF,1} = 0.52\)</span>.</p>
<center>
<div class="figure">
<img src="fftestOutput.png" id="fig:kstest2D" alt=""><p class="caption"><strong>Figure 3</strong> | Illustration of the Fasano–Franceschini algorithmic
search for the maximal difference (<span class="math inline">\(D_{FF,1}\)</span>) between sample 2-D eCDFs.
Looping through each point in the sampled data to define a unique origin
(grey dotted line), the fraction of orange and blue points in each
quadrants are computed (plot corners). For each origin, the quadrant
which maximizes the absolute difference in the integrated probabilities
is indicated. The origin which maximizes the overall absolute difference
in the integrated probabilities between samples is highlighted by the
orange box.</p>
</div>
</center>
<p>This process is repeated using the points from <em>other</em> sample as the
origins to compute the maximal <span class="math inline">\(D_{FF,2}\)</span> with origins from the second
sample. <span class="math inline">\(D_{FF,1}\)</span> and <span class="math inline">\(D_{FF,2}\)</span> are then averaged to compute the
overall <span class="math inline">\(D_{FF}\)</span> for hypothesis testing, <span class="math inline">\(D_{FF}=(D_{FF,1}+D_{FF,2})/2\)</span>.</p>
<p>It may be that some points are tied with the <span class="math inline">\(X\)</span> and/or <span class="math inline">\(Y\)</span> coordinates
of the origin, creating an ambiguity when computing the fraction of
points in each quadrant. Since the test attempts to define the maximal
difference of the cumulative probabilities, a natural solution would be
to treat a point that is tied with the current <span class="math inline">\(X\)</span> and/or <span class="math inline">\(Y\)</span>
coordinates of the origin as equally likely to have been drawn from any
of the tied quadrants. Hence, any data point sharing the same <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span>
coordinate as the origin is evenly distributed across the tied
quadrants, with each of the two quadrants receiving half a count. Any
data point sharing the both the same <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> coordinates as the
current origin (including the origin itself) is evenly distributed
across all quadrants, with all four quadrants receiving a quarter count.</p>
</div>
<div id="null-distribution-of-d_ff" class="section level2">
<h2 class="hasAnchor">
<a href="#null-distribution-of-d_ff" class="anchor"></a>Null distribution of <span class="math inline">\(D_{FF}\)</span>
</h2>
<p>Using Monte Carlo simulation, Fasano and Franceschini created a look-up
table of critical values of <span class="math inline">\(D_{FF}\)</span> as a function of <span class="math inline">\(D_{FF}\)</span>, the
sample size, and the coefficient of correlation <span class="math inline">\(r\)</span>. <span class="citation">(<a href="#ref-numericalRecipes" role="doc-biblioref">18</a>)</span>
later defined an approximate fit to the lookup table as follows. For a
single sample of size <span class="math inline">\(n\)</span>,</p>
<span class="math display" id="eq:4">\[\begin{equation}
\mathbb{P}(d_{FF} &gt; D_{FF}) = \Phi \left( \frac{D_{FF}\sqrt{n}}{1+\sqrt{1-r^2}(0.25-0.75/\sqrt{n})} \right) \, .
\tag{4}
\end{equation}\]</span>
<p>where <span class="math inline">\(\Phi(\cdot)\)</span> is as defined in Eq
<a href="#eq:1" reference-type="ref" reference="eq:1">1</a>. The two sample
case uses the same formula as above, but with the slight variation where</p>
<span class="math display" id="eq:5">\[\begin{equation}
n = \frac{n_1n_2}{n_1+n_2}\, .
\tag{5}
\end{equation}\]</span>
<p>In both cases, <span class="math inline">\(r\)</span> is defined in the
usual way as</p>
<span class="math display" id="eq:6">\[\begin{equation}
r = \frac{\sum_{i}(X_i-\bar{X})(Y_i-\bar{Y})}{\sqrt{\sum_{i}(X_i-\bar{X})^2}\sqrt{\sum_{i}(Y_i-\bar{Y})^2}}\, .
\tag{6}
\end{equation}\]</span>
</div>
</div>
<div id="sec:illustrations" class="section level1">
<h1 class="hasAnchor">
<a href="#sec:illustrations" class="anchor"></a>Illustrations</h1>
<div id="fasanofranceschini-test-usage" class="section level2">
<h2 class="hasAnchor">
<a href="#fasanofranceschini-test-usage" class="anchor"></a>Fasano–Franceschini test usage</h2>
<p>In their paper, Fasano and Franceschini use Monte Carlo simulation to
approximate the distribution of <span class="math inline">\(D_{FF}\)</span> as a function of the sample
size <span class="math inline">\(n\)</span> and the coefficient of correlation <span class="math inline">\(r\)</span>. Notably, unlike the 1-D
KS test, the distribution of <span class="math inline">\(D_{FF}\)</span> is <em>not</em> completely independent of
the shape of the 2-D distribution of the underlying data, but depends on
the correlations between the variables. In the case where the variables
<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are perfectly correlated (<span class="math inline">\(r = 1\)</span>), the 2-D distribution
lies along a single line and thus the 1-D KS test could be used; at the
other extreme were <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are perfectly uncorrelated (<span class="math inline">\(r = 0\)</span>), the
2-D distribution is independent in the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> directions and one
could apply the 1-D KS test on the marginal distributions. Results from
Monte Carlo simulation support these expectations, showing that the
distribution of <span class="math inline">\(D\)</span> is nearly identical for varying distributions with
the same correlation coefficient <span class="citation">(<a href="#ref-Fasano1987" role="doc-biblioref">1</a>)</span>. The approximation by
<span class="citation">(<a href="#ref-numericalRecipes" role="doc-biblioref">18</a>)</span> (Eq <a href="#eq:4" reference-type="ref" reference="eq:4">4</a>–<a href="#eq:5" reference-type="ref" reference="eq:5">5</a>) can be used to test the significance levels for the
2-D K-S test using the following code:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/nesscoder/fasano.franceschini.test">fasano.franceschini.test</a></span><span class="op">)</span>

<span class="co">#set seed for reproducible example</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>

<span class="co">#create 2-D samples with the same underlying distributions</span>
<span class="va">sample1Data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">sample2Data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="op">)</span>

<span class="fu"><a href="../reference/fasano.franceschini.test.html">fasano.franceschini.test</a></span><span class="op">(</span>S1 <span class="op">=</span> <span class="va">sample1Data</span>, S2 <span class="op">=</span> <span class="va">sample2Data</span><span class="op">)</span></code></pre></div>
<pre><code>## 
##  Fasano-Francheschini Test
## 
## data:  sample1Data and sample2Data
## D-stat = 0.4, p-value = 0.3091
## sample estimates:
## dff,1 dff,2 
## 0.375 0.425</code></pre>
</div>
<div id="bootstrap-version-of-the-fasanofranceschini-test" class="section level2">
<h2 class="hasAnchor">
<a href="#bootstrap-version-of-the-fasanofranceschini-test" class="anchor"></a>Bootstrap version of the Fasano–Franceschini test</h2>
<p>It has been noted that the approximation from <span class="citation">(<a href="#ref-numericalRecipes" role="doc-biblioref">18</a>)</span> is only
accurate when <span class="math inline">\(n \gtrsim 20\)</span> and the <span class="math inline">\(p\)</span>-value is less than (more
significant than) <span class="math inline">\(\sim 0.2\)</span> <span class="citation">(<a href="#ref-Babu2006" role="doc-biblioref">19</a>)</span>. While this inaccuracy still
allows a simple rejection decision to be made at any <span class="math inline">\(\alpha\leq0.2\)</span>, it
is sometimes useful to quantify large <span class="math inline">\(p\)</span> more exactly (such as if one
was to do a cross-study concordance analysis comparing <span class="math inline">\(p\)</span> values
between studies as in <span class="citation">(<a href="#ref-Ness-Cohn2020" role="doc-biblioref">22</a>)</span>), and to apply it to smaller
datasets. To address these limitations, one can bootstrap the
significance levels for the particular multidimensional statistic
directly from the particular data set under study. As Fasano and
Franceschini’s paper was originally released in 1987, this approach was
unfeasible at scale. Today, modern computers can rapidly compute a
bootstrapped null distribution of <span class="math inline">\(D_{FF}\)</span> from the data to test
significance.</p>
<p>The <code>fasano.franceschini.test</code> <strong>R</strong> package implements a parallelized bootstrapping procedure. The
marginal distribution from 2-dimensional data set is resampled with
replacement to generate randomized 2-dimensional data sets <code>nBootStrap</code> times. The
frequency count by quadrant is performed for each bootstrapped
resampling as described above to compute the <span class="math inline">\(D_{FF}\)</span>. The observed
<span class="math inline">\(D_{FF}\)</span> is then compared to the distribution of bootstrapped <span class="math inline">\(D_{FF}\)</span>
to compute a <span class="math inline">\(p\)</span> value. The bootstrapped version of the
Fasano–Franceschini test can be run as follows (see <code><a href="../reference/fasano.franceschini.test.html">fasano.franceschini.test()</a></code> for further source
code details and implementation).</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#set seed for reproducible example</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>

<span class="co">#create 2-D samples with the same underlying distributions</span>
<span class="va">sample1Data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">sample2Data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="op">)</span>

<span class="fu"><a href="../reference/fasano.franceschini.test.html">fasano.franceschini.test</a></span><span class="op">(</span>S1 <span class="op">=</span> <span class="va">sample1Data</span>, S2 <span class="op">=</span> <span class="va">sample2Data</span>, nBootstrap <span class="op">=</span> <span class="fl">10</span>, cores <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<pre><code>## 
##  Fasano-Francheschini Test
## 
## data:  sample1Data and sample2Data
## D-stat = 0.4, p-value = 0.2727
## sample estimates:
## dff,1 dff,2 
## 0.375 0.425</code></pre>
<p>To improve run time, one may adjust the <code>cores</code> parameter; see the R <code>parallel</code> package and
<code>mcapply()</code> the function for further details.</p>
</div>
<div id="computational-efficency" class="section level2">
<h2 class="hasAnchor">
<a href="#computational-efficency" class="anchor"></a>Computational efficency</h2>
<center>
<div class="figure">
<img src="benchmark.png" id="fig:bmark" align="center" style="width:75.0%" alt=""><p class="caption"><strong>Figure 4</strong> | Computational efficiency benchmarks. <strong>A:</strong> Runtime of
the Fasano–Franceschini test relative to the Peacock test at four
different sample sizes (<span class="math inline">\(n=10, 100, 1000, 5000\)</span>). Points represent the
average of 10 benchmark runs. <strong>B:</strong> Runtime of the Fasano–Franceschini
bootstrapping procedure for various sample sizes
(<span class="math inline">\(n= 10, 100, 1000, 5000\)</span>) as a function of the number of cores used.
Within each panel, lines are colored by the number of bootstrap
iterations (no bootstrap, 10, 100, 1000). Points represent the average
of 10 benchmark runs. Note the logarithmic <span class="math inline">\(y\)</span>-axis in
(B).</p>
</div>
</center>
<p>To assess the computational efficiency, we benchmarked the package as
follows. Using the <code>rbenchmark</code> package to evaluate runtime, the Fasano–Franceschini
test and Peacock test were run under four different samples sizes
(<span class="math inline">\(n=10, 100, 1000, 5000\)</span>), with 10 replicates for each run. The
Fasano–Franceschini test bootstrap procedure was further evaluated
under four different bootstrap iterations (no bootstrap, 10, 100, 1000),
again using 10 replicates for each run. Reported results represent the
average run time of the 10 replicate benchmarks. All benchmark tests
were run on a 2018 macBook Pro Mac (macOS Catalina) with a 2.7-GHz
Quad-Core Intel Core i7 processor and 16 GB of 2133 MHz LPDDR3 memory.</p>
<p>The main distinction between the Peacock and Fasano–Franceschini tests
is in computational efficiency, with Fasano–Franceschini scaling as
<span class="math inline">\(O(n^2)\)</span> relative to Peacock’s complexity of <span class="math inline">\(O(n^3)\)</span> <span class="citation">(<a href="#ref-Lopes2007" role="doc-biblioref">17</a>)</span>. Our
benchmarks also show this advantage, as shown in <strong>Figure
<a href="#fig:bmark" reference-type="ref" reference="fig:bmark">4</a>A</strong>. While
the implementation of the bootstrapping procedure increases runtime in
comparison to the approximate fit from <span class="citation">(<a href="#ref-numericalRecipes" role="doc-biblioref">18</a>)</span>,
parallelization of the Fasano–Franceschini test shows a four-fold
reduction in run time when parallelized across 8 cores (<strong>Figure
<a href="#fig:bmark" reference-type="ref" reference="fig:bmark">4</a>B</strong>).</p>
</div>
</div>
<div id="sec:summary" class="section level1">
<h1 class="hasAnchor">
<a href="#sec:summary" class="anchor"></a>Summary and discussion</h1>
<p>The <code>fasano.franceschini.test</code> package is an <strong>R</strong> implementation of the 2-D two-sample KS test as
defined by Fasano and Franceschini <span class="citation">(<a href="#ref-Fasano1987" role="doc-biblioref">1</a>)</span>. It improves upon
existing packages by implementing a fast algorithm and a parallelized
bootstrapping procedure for improved statistical testing. Complete
package documentation and source code is available via the Comprehensive
<strong>R</strong> Archive Network (CRAN) at <a href="https://CRAN.R-project.org/" class="uri">https://CRAN.R-project.org/</a> and the package
website at <a href="https://nesscoder.github.io/fasano.franceschini.test/" class="uri">https://nesscoder.github.io/fasano.franceschini.test/</a>.</p>
</div>
<div id="computational-details" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#computational-details" class="anchor"></a>Computational details</h1>
<p>The results in this paper were obtained using <strong>R</strong> 4.0.3 with the fasano.franceschini.test 1.0.0
package. <strong>R</strong> itself and all package dependencies (methods 4.0.3; parallel 4.0.3) are
available from the Comprehensive Archive Network (CRAN) at
<a href="https://CRAN.R-project.org/" class="uri">https://CRAN.R-project.org/</a>.</p>
</div>
<div id="acknowledgments" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#acknowledgments" class="anchor"></a>Acknowledgments</h1>
<p>Research reported in this publication was supported by the NSF-Simons
Center for Quantitative Biology at Northwestern University, an
NSF-Simons MathBioSys Research Center. This work was supported by a
grant from the Simons Foundation/SFARI (597491-RWC) and the National
Science Foundation (1764421). The content is solely the responsibility
of the authors and does not necessarily represent the official views of
the National Science Foundation and Simons Foundation.</p>
<p>E.N.C developed the <code>fasano.franceschini.test</code> package and produced the tutorials/documentation;
E.N.C. and R.B. wrote the paper.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references csl-bib-body">
<div id="ref-Fasano1987" class="csl-entry">
<div class="csl-left-margin">1. </div>
<div class="csl-right-inline">G. Fasano, A. Franceschini, A multidimensional version of the kolmogorov-smirnov test. <em>Monthly Notices of the Royal Astronomical Society</em> <strong>225</strong>, 155–170 (1987).</div>
</div>
<div id="ref-Kolmogorov1933" class="csl-entry">
<div class="csl-left-margin">2. </div>
<div class="csl-right-inline">A. N. Kolmogorov, <span class="nocase">Sulla Determinazione Empirica di Una Legge di Distribuzione</span>. <em>Giornale dell’Istituto Italiano degli Attuari</em>, 83–91 (1933).</div>
</div>
<div id="ref-Kolmogorov1933a" class="csl-entry">
<div class="csl-left-margin">3. </div>
<div class="csl-right-inline">A. N. Kolmogorov, <span class="nocase">Über die Grenzwertsätze der Wahrscheinlichkeitsrechnung</span>. <em><span>Bull. Acad. Sci. URSS</span></em> <strong>1933</strong>, 363–372 (1933).</div>
</div>
<div id="ref-Smirnov1936" class="csl-entry">
<div class="csl-left-margin">4. </div>
<div class="csl-right-inline">N. V. Smirnov, <span class="nocase">Sur la distribution de <span class="math inline">\(\omega^2\)</span> (criterium de M.R. v. Mises)</span>. <em>Com. Rend. Acad. Sci. (Paris)</em> <strong>202</strong>, 449–452 (1936).</div>
</div>
<div id="ref-Smirnov1937" class="csl-entry">
<div class="csl-left-margin">5. </div>
<div class="csl-right-inline">N. V. Smirnov, On the distribution of the mises <span class="math inline">\(\omega^2\)</span> criterion [in <span>Russian</span>]. <em><span>Rec. Math. N.S. [Mat. Sbornik]</span></em> <strong>2</strong>, 973–993 (1937).</div>
</div>
<div id="ref-Smirnov1939" class="csl-entry">
<div class="csl-left-margin">6. </div>
<div class="csl-right-inline">N. V. Smirnov, On the deviations of the empirical distribution curve [in <span>Russian</span>]. <em><span>Rec. Math. N.S. [Mat. Sbornik]</span></em> <strong>6</strong>, 3–26 (1939).</div>
</div>
<div id="ref-Smirnov1944" class="csl-entry">
<div class="csl-left-margin">7. </div>
<div class="csl-right-inline">N. V. Smirnov, Approximate laws of distribution of random variables from empirical data. <em><span>Uspehi Matem. Nauk</span></em> <strong>10</strong>, 179–206 (1944).</div>
</div>
<div id="ref-Smirnov1948" class="csl-entry">
<div class="csl-left-margin">8. </div>
<div class="csl-right-inline">N. V. Smirnov, Table for estimating the goodness of fit of empirical distributions. <em>The Annals of Mathematical Statistics</em> (1948) https:/doi.org/<a href="https://doi.org/10.1214/aoms/1177730256">10.1214/aoms/1177730256</a>.</div>
</div>
<div id="ref-Atasoy2017" class="csl-entry">
<div class="csl-left-margin">9. </div>
<div class="csl-right-inline">S. Atasoy, <em>et al.</em>, Connectome-harmonic decomposition of human brain activity reveals dynamical repertoire re-organization under LSD. <em>Scientific Reports</em> <strong>7</strong>, 1–18 (2017).</div>
</div>
<div id="ref-Chiang2018" class="csl-entry">
<div class="csl-left-margin">10. </div>
<div class="csl-right-inline">F. Chiang, O. Mazdiyasni, A. AghaKouchak, Amplified warming of droughts in southern united states in observations and model simulations. <em>Science Advances</em> <strong>4</strong>, eaat2380 (2018).</div>
</div>
<div id="ref-Hahne2018" class="csl-entry">
<div class="csl-left-margin">11. </div>
<div class="csl-right-inline">J. M. Hahne, M. A. Schweisfurth, M. Koppe, D. Farina, Simultaneous control of multiple functions of bionic hand prostheses: Performance and robustness in end users. <em>Science Robotics</em> <strong>3</strong> (2018).</div>
</div>
<div id="ref-Hargreaves2020" class="csl-entry">
<div class="csl-left-margin">12. </div>
<div class="csl-right-inline">S. M. Hargreaves, W. M. C. Araújo, E. Y. Nakano, R. P. Zandonadi, Brazilian vegetarians diet quality markers and comparison with the general population: A nationwide cross-sectional study. <em><span>PloS</span> One</em> <strong>15</strong>, e0232954 (2020).</div>
</div>
<div id="ref-Wong2020" class="csl-entry">
<div class="csl-left-margin">13. </div>
<div class="csl-right-inline">F. Wong, J. J. Collins, Evidence that coronavirus superspreading is fat-tailed. <em>Proceedings of the National Academy of Sciences</em> <strong>117</strong>, 29416–29418 (2020).</div>
</div>
<div id="ref-Kaczanowska2021" class="csl-entry">
<div class="csl-left-margin">14. </div>
<div class="csl-right-inline">S. Kaczanowska, <em>et al.</em>, Genetically engineered myeloid cells rebalance the core immune suppression program in metastasis. <em>Cell</em> <strong>184</strong>, 2033–2052 (2021).</div>
</div>
<div id="ref-Peacock1983" class="csl-entry">
<div class="csl-left-margin">15. </div>
<div class="csl-right-inline">J. A. Peacock, Two-dimensional goodness-of-fit testing in astronomy. <em>Monthly Notices of the Royal Astronomical Society</em> <strong>202</strong>, 615–627 (1983).</div>
</div>
<div id="ref-R" class="csl-entry">
<div class="csl-left-margin">16. </div>
<div class="csl-right-inline">R Core Team, <em><span>R</span>: <span>A</span> language and environment for statistical computing</em> (<span>R</span> Foundation for Statistical Computing, 2020).</div>
</div>
<div id="ref-Lopes2007" class="csl-entry">
<div class="csl-left-margin">17. </div>
<div class="csl-right-inline">R. H. C. Lopes, I. Reid, P. R. Hobson, The two-dimensional <span>Kolmogorov</span>-<span>Smirnov</span> test in <em>XI International Workshop on Advanced Computing and Analysis Techniques in Physics Research</em>, (2007).</div>
</div>
<div id="ref-numericalRecipes" class="csl-entry">
<div class="csl-left-margin">18. </div>
<div class="csl-right-inline">W. H. Press, S. A. Teukolsky, W. T. Vetterling, B. P. Flannery, <em>Numerical recipes 3rd edition: The art of scientific computing</em>, 3rd Ed. (Cambridge University Press, 2007).</div>
</div>
<div id="ref-Babu2006" class="csl-entry">
<div class="csl-left-margin">19. </div>
<div class="csl-right-inline">G. Babu, E. Feigelson, Astrostatistics: Goodness-of-fit and all that! in <em>Astronomical Data Analysis Software and Systems XV</em>, (2006), p. 127.</div>
</div>
<div id="ref-Stephens1992a" class="csl-entry">
<div class="csl-left-margin">20. </div>
<div class="csl-right-inline">M. A. Stephens, <span>“<span class="nocase">Introduction to Kolmogorov (1933) On the Empirical Determination of a Distribution</span>”</span> in (Springer, New York, NY, 1992), pp. 93–105.</div>
</div>
<div id="ref-Kendall1946" class="csl-entry">
<div class="csl-left-margin">21. </div>
<div class="csl-right-inline">M. G. Kendall, A. Stuart, <em><span class="nocase">The Advanced Theory of Statistics</span></em> (Griffin, 1946).</div>
</div>
<div id="ref-Ness-Cohn2020" class="csl-entry">
<div class="csl-left-margin">22. </div>
<div class="csl-right-inline">E. Ness-Cohn, M. Iwanaszko, W. L. Kath, R. Allada, R. Braun, <span>TimeTrial</span>: An interactive application for optimizing the design and analysis of transcriptomic time-series data in circadian biology research. <em>Journal of Biological Rhythms</em> <strong>35</strong>, 439–451 (2020).</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by <a href="https://sites.northwestern.edu/elannesscohn/">Elan Ness-Cohn</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
